{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# This script is used to make the \"WHAM meta files\" from the umbrella files.\n",
    "# The Eric Theide python implementation of EMUS seems to work best with this format\n",
    "\n",
    "import sys, os, os.path\n",
    "import glob\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "from emus import usutils as uu\n",
    "from emus import emus, avar\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pp\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import yt\n",
    "from yt.frontends.boxlib.data_structures import AMReXDataset\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After phi_0 and \\kappa data has been extracted using \"Extract_Data.ipynb\", load data from the folder \n",
    "# with umbrella files that have had this data removed. \n",
    "\n",
    "\n",
    "\n",
    "# the block below computes the number of samples in the umbrella files ( assuming they all have the same amount)\n",
    "location='./umb_files' #data file location. A copy of the data should be used. \n",
    "list = sorted(os.listdir(\"./umb_files\"))\n",
    "Number_of_Umbrellas=len(list) \n",
    "dat = np.loadtxt('./umb_files/umbrella00000000.txt',usecols=[0],unpack=True) #any of the files should work\n",
    "Number_of_Samples_in_Umb=dat.shape[0]\n",
    "\n",
    "\n",
    "#load umbrella parameters\n",
    "centers = np.loadtxt('phi0_centers.txt')\n",
    "fks = np.loadtxt('spring_constants.txt')\n",
    "\n",
    "# Additonal EMUS parameters should be set here\n",
    "period=None\n",
    "dim=1\n",
    "T=0.01\n",
    "k_B=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hold  umbrella data in 2D array with column index corresponding to umbrella index.\n",
    "dat_array=numpy.zeros(shape=(Number_of_Samples_in_Umb,Number_of_Umbrellas),dtype=float64)\n",
    "H_data=numpy.zeros(shape=(Number_of_Samples_in_Umb,Number_of_Umbrellas),dtype=float64)\n",
    "No_umb_H_data=numpy.zeros(shape=(Number_of_Samples_in_Umb,Number_of_Umbrellas),dtype=float64)\n",
    "i=0\n",
    "for filename in list:    \n",
    "    a=os.path.join(location, filename)\n",
    "    Temp=np.loadtxt(a)\n",
    "    dat_array[:,i]=Temp[:,0]\n",
    "    H_data[:,i]=Temp[:,2]\n",
    "    No_umb_H_data[:,i]=Temp[:,1]\n",
    "    i=i+1\n",
    "\n",
    "# Data is then reformatted that it is made compatible with EMUS struvture \n",
    "# This follows the format of their example in their github repo\n",
    "# Essentially, every first index should correspond to all the data in that umbrella\n",
    "cv_data=numpy.zeros(shape=(Number_of_Umbrellas,Number_of_Samples_in_Umb,),dtype=float64)\n",
    "Hamiltonian=numpy.zeros(shape=(Number_of_Umbrellas,Number_of_Samples_in_Umb,),dtype=float64)\n",
    "Ham_no_umb=numpy.zeros(shape=(Number_of_Umbrellas,Number_of_Samples_in_Umb,),dtype=float64)\n",
    "\n",
    "for i in range (0,Number_of_Umbrellas):\n",
    "    cv_data[i]=dat_array[0:Number_of_Samples_in_Umb,i]\n",
    "    Hamiltonian[i]=H_data[0:Number_of_Samples_in_Umb,i]\n",
    "    Ham_no_umb[i]=No_umb_H_data[0:Number_of_Samples_in_Umb,i]\n",
    "    \n",
    "    \n",
    "list2=[0]*(len(list))\n",
    "i=0\n",
    "for filename in list:    \n",
    "    list2[i]=os.path.join(location, filename)   \n",
    "    i=i+1    \n",
    "cv_traj=(cv_data)\n",
    "list2=np.asarray(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A folder in the \"WHAM meta file\" format will be made\n",
    "# This is a format that is standard for chemistry people\n",
    "# EMUS is easier to work with in this format\n",
    "# See WHAM documentation of grossfield for a precise description\n",
    "\n",
    "\n",
    "# Switch location to a new copy of original data file with title denoting the WHAM format\n",
    "location='./umb_files_Wham_Format' #data file location\n",
    "list = sorted(os.listdir(\"./umb_files_Wham_Format\"))\n",
    "list3=[0]*(len(list))\n",
    "i=0\n",
    "for filename in list:    \n",
    "    list3[i]=os.path.join(location, filename)   \n",
    "    i=i+1\n",
    "\n",
    "    \n",
    "## code below is for removing the last two THREE of the data files(none phi average part).\n",
    "## ONLY RUN ONCE on the NON-original data \n",
    "\n",
    "# temp=np.zeros(Number_of_Samples_in_Umb)    \n",
    "# for filename in list3:    \n",
    "#     with open(filename, 'r') as fin:\n",
    "#         data = fin.read().splitlines(True)\n",
    "#         for j in range (0,Number_of_Samples_in_Umb):\n",
    "#             temp[j]=float(data[j][0:20])\n",
    "#         with open(filename, 'w') as fout:\n",
    "#             np.savetxt(fout, temp, fmt=\"%10.14f\",delimiter='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add time column to trimmed data set. \n",
    "##*****RUN ONCE******#\n",
    "\n",
    "# DT=2.4414e-5 # time step used in run\n",
    "# DT_vec=np.arange(Number_of_Samples_in_Umb)+1\n",
    "# DT_vec=DT_vec*DT # create a vector of these timesteps (i.e dt,2*dt,3*dt,...)\n",
    "\n",
    "\n",
    "# # Add time step column to data as a column before the phi averages column\n",
    "\n",
    "\n",
    "# for filename in list3: \n",
    "#     with open(filename, 'r') as fin:\n",
    "#         data = fin.read().splitlines(True)\n",
    "#         data=np.asarray(data)\n",
    "#         Place_holder = np.zeros(data.size, dtype=[('var1', float64), ('var2', float64)])\n",
    "#         Place_holder['var1']=DT_vec\n",
    "#         Place_holder['var2']=data\n",
    "#         np.savetxt(filename, Place_holder, fmt=\"%10.12f %10.12f\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we find the \"middle\" of the data where our loop is made.\n",
    "# The location prints to screen\n",
    "\n",
    "# Depending on the where the \"turning point\" of the average data is, find the max or min \n",
    "A=np.where(centers == centers.min())  # find min since we go from 1.0 to 0.74 to 1.0\n",
    "# np.where(centers == centers.min())\n",
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET middle location index manually here\n",
    "middle=171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite copy of umbrella file with time step and phi average with WHAM format of data\n",
    "\n",
    "#In this case we consider data with 2 pars. The 1.0 to 0.74 trip, and the 0.74 to 1.0 trip.\n",
    "\n",
    "# We make two meta files for this\n",
    "\n",
    "#part 1 (1.0 to 0.74)\n",
    "\n",
    "list4=np.asarray(list3[0:middle+1])        \n",
    "MAKE_WHAM_META_ARR = np.zeros(list4.size, dtype=[('var1', 'U60'), ('var2', float64), ('var3', float64)])\n",
    "MAKE_WHAM_META_ARR['var1']=list4[0:middle+1]\n",
    "MAKE_WHAM_META_ARR['var2']=centers[0:middle+1]\n",
    "MAKE_WHAM_META_ARR['var3']=fks[0:middle+1]\n",
    "np.savetxt('ONE_TO_074_META.txt', MAKE_WHAM_META_ARR, fmt=\"%60s %10.8f %10.8f\",delimiter='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2 (0.74 to 1.0)\n",
    "\n",
    "list5=np.asarray(list3[middle+1:])        \n",
    "MAKE_WHAM_META_ARR_2 = np.zeros(list5.size, dtype=[('var1', 'U60'), ('var2', float64), ('var3', float64)])\n",
    "MAKE_WHAM_META_ARR_2['var1']=list5\n",
    "MAKE_WHAM_META_ARR_2['var2']=centers[middle+1:]\n",
    "MAKE_WHAM_META_ARR_2['var3']=fks[middle+1:]\n",
    "np.savetxt('074_TO_ONE_META.txt', MAKE_WHAM_META_ARR_2, fmt=\"%60s %10.8f %10.8f\",delimiter='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = 'ONE_TO_074_META.txt'         # Path to Meta File\n",
    "psis, cv_trajs, neighbors = uu.data_from_meta(\n",
    "    meta_file, dim, T=T, k_B=k_B, period=period)\n",
    "\n",
    "\n",
    "meta_file = '074_TO_ONE_META.txt'         # Path to Meta File\n",
    "psis, cv_trajs, neighbors = uu.data_from_meta(\n",
    "    meta_file, dim, T=T, k_B=k_B, period=period)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
