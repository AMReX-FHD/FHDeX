{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Exploration of Fluctuating Channel Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a sandbox for exploring the fluctuating channel flow data. Data is loaded using the YT package. You might need to install (using `pip`):\n",
    "1. Jupyter (and Jupyter Lab)\n",
    "2. YT\n",
    "3. numpy\n",
    "4. matplotlib\n",
    "\n",
    "... Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49ca7ef16c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAMReXDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;31m# In case anyone wishes to use it by name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuncs\u001b[0m \u001b[0;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mget_memory_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/funcs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mYTEquivalentDimsError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myt_array\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYTArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYTQuantity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/units/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munit_symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mphysical_constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myt_array\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYTQuantity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/units/unit_symbols.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# The full license is in the file COPYING.txt, distributed with this software.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myt_array\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYTQuantity\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mquan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/units/yt_array.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlru_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnumeric_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_demand_imports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_astropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/utilities/on_demand_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m \u001b[0m_h5py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py_imports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mnose_imports\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/yt/utilities/on_demand_imports.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2.4.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 self._err = RuntimeError(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0m_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilence_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_converters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pxd\u001b[0m in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "import sys, os, os.path\n",
    "import glob\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "import yt\n",
    "from yt.frontends.boxlib.data_structures import AMReXDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inline plots and namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%precision %e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `phi` with `concentration` in plot file's header file (yt doesn't like `phi`...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace \"phi\" with \"concentration\" in plt header file (yt doesn't like phi...)\n",
    "def substitute_header(plt_file, source=\"phi\", target=\"con\"):\n",
    "    \n",
    "    # load header file\n",
    "    header_file = os.path.join(plt_file, \"Header\")\n",
    "    with open(header_file, \"r\") as f:\n",
    "        header_orig = f.readlines()\n",
    "    \n",
    "    # select variable lables\n",
    "    n_lables   = int(header_orig[1])\n",
    "    l_offset   = 2\n",
    "    \n",
    "    # make a backup copy(iff the source was found in original)\n",
    "    if source+\"\\n\" in header_orig:\n",
    "        header_cpy  = os.path.join(plt_file, \"Header.backup\")\n",
    "        with open(header_cpy, \"w\") as f:\n",
    "            for line in header_orig:\n",
    "                f.write(line)\n",
    "    \n",
    "    # replace source with target\n",
    "    for i in range(l_offset, n_lables+l_offset):\n",
    "        if header_orig[i] == source+\"\\n\":\n",
    "            header_orig[i] = target+\"\\n\"\n",
    "    \n",
    "    # save substituted file in place of original\n",
    "    with open(header_file, \"w\") as f:\n",
    "        for line in header_orig:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we're working in the same directory as a the data $=>$ look in `.` for plot files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \".\"\n",
    "data_dir  = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_root, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fill   = 5\n",
    "prefix   = \"plt\"\n",
    "file_fmt = prefix + \"{:0\" + str(n_fill) + \"d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glob  = os.path.join(data_path, prefix + \"*\")\n",
    "data_files = glob.glob(data_glob)\n",
    "data_files.sort()\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Final State of the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_index(data_file, str_field, str_coord):\n",
    "    substitute_header(data_file)\n",
    "    \n",
    "    # Loads the data file\n",
    "    ds = yt.load(data_file)\n",
    "    \n",
    "    # Takes a slice perpendicular to the coordinate represented by `str_coord`\n",
    "    # -> the slice is at the center of the box.\n",
    "    # -> the data field being sliced has to have the same name as `str_field`\n",
    "    slc = yt.SlicePlot(ds, str_coord, str_field)\n",
    "    \n",
    "    # Set the plotted variable to log scale\n",
    "    #slc.set_log(str_field, True)\n",
    "    \n",
    "    # Show data\n",
    "    slc.show()\n",
    "    #slc.save(\"step_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out what fields are contained in the plot file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = yt.load(data_files[-1])\n",
    "ds.field_list\n",
    "ds.domain_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the last plot file's $y$-velocity (slicing normal the $y$-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_index(data_files[-1], \"shifted_vely\", \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the presure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_index(data_files[-1], \"pres\", \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... with `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = yt.load(data_files[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information about geometry: $\\mathrm{d}x$ and index of centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.array(\n",
    "    [\n",
    "        ( ds.domain_right_edge[i] - ds.domain_left_edge[i] ) / ds.domain_dimensions[i] \n",
    "        for i in range(ds.dimensionality) \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "centre_slice = np.array([ei for ei in ds.domain_right_edge ])/2\n",
    "ind_cen      = centre_slice / dx\n",
    "print(ind_cen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a \"cube of data\" from the plot file. This might seem a bit convoluted, but remember that YT is built to handle multi-level data. This function covers a given level (in our case, level 0) with a 3D grid (cube) and exports the data into a dict of `numpy` arrays. This way `cube[\"filed name\"]` is a 3D numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = ds.covering_grid(level=0, fields=[\"shifted_velx\", \"shifted_vely\", \"shifted_velz\"], \n",
    "                        left_edge=ds.domain_left_edge, dims=ds.domain_dimensions)\n",
    "velx = cube[\"shifted_velx\"]\n",
    "vely = cube[\"shifted_vely\"]\n",
    "velz = cube[\"shifted_velz\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(velx[:, 16, :])\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(vely[:, 16, :])\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(velz[:, 16, :])\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoA:\n",
    "    _pref = \"particle_\"\n",
    "    _pos  = \"position_\"\n",
    "    _vel  = \"vel\"\n",
    "# New here\n",
    "    _id   = \"id\"\n",
    "    _cpu  = \"cpu\"\n",
    "    _id_0 = \"id_0\"\n",
    "    _cpu_0 = \"cpu_0\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        str_pos = self._pref+self._pos\n",
    "        self.px = np.array(data[str_pos + \"x\"])\n",
    "        self.py = np.array(data[str_pos + \"y\"])\n",
    "        self.pz = np.array(data[str_pos + \"z\"])\n",
    "\n",
    "        str_vel = self._pref+self._vel\n",
    "        self.vx = np.array(data[str_vel + \"x\"])\n",
    "        self.vy = np.array(data[str_vel + \"y\"])\n",
    "        self.vz = np.array(data[str_vel + \"z\"])\n",
    "\n",
    "        str_id = self._pref+self._id\n",
    "        self.id = np.array(data[str_id])\n",
    "        str_cpu = self._pref+self._cpu\n",
    "        self.cpu = np.array(data[str_cpu])\n",
    "        \n",
    "        str_id_0 = self._pref+self._id_0\n",
    "        self.id_0 = np.array(data[str_id_0])\n",
    "        str_cpu_0 = self._pref+self._cpu_0\n",
    "        self.cpu_0 = np.array(data[str_cpu_0])\n",
    " \n",
    "# new here\n",
    "    def __str__(self):\n",
    "        return \"{pos:\"  + str(self.px) + \",\" + str(self.py) + \",\" + str(self.pz) + \\\n",
    "              \"; vel:\"  + str(self.vx) + \",\" + str(self.vy) + \",\" + str(self.vz) + \\\n",
    "              \"; id:\"   + str(self.id) + \", cpu:\" + str(self.cpu) + \", id_0:\" + str(self.id_0) + \", cpu_0:\" + str(self.cpu_0) + \",\" + \"}\"\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "# new here\n",
    "class Particle:\n",
    "    def __init__(self, px, py, pz, vx, vy, vz, id, cpu, id_0, cpu_0):\n",
    "        self.pos = np.array([px, py, pz])\n",
    "        self.vel = np.array([vx, vy, vz])\n",
    "        self.id  = np.array(id)\n",
    "        self.cpu  = np.array(cpu)\n",
    "        self.id_0  = np.array(id_0)\n",
    "        self.cpu_0  = np.array(cpu_0)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"P(\" + str(self.pos) + \",\" + str(self.vel) + \",\" + str(self.id) + \",\" + str(self.cpu) + \",\" + str(self.id_0) + \",\" + str(self.cpu_0) + \",\" + \")\"\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "class AoS:\n",
    "    def __init__(self, amrex_data):\n",
    "        self.particles = list()\n",
    "        soa = SoA(amrex_data)\n",
    "# new here        \n",
    "        data = zip(soa.px, soa.py, soa.pz, soa.vx, soa.vy, soa.vz, soa.id, soa.cpu, soa.id_0, soa.cpu_0)\n",
    "        for elt in data:\n",
    "            self.particles.append(Particle(* elt))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = AMReXDataset(data_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.particle_fields_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = ds.all_data()\n",
    "soa = SoA(ad)\n",
    "aos = AoS(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aos.particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop = 10#number of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aos.particles[0].pos[0:nop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_ = dict()\n",
    "id_        = dict()\n",
    "cpu_       = dict()\n",
    "id0_       = dict()\n",
    "cpu0_      = dict()\n",
    "\n",
    "for x in range(1,nop+1):\n",
    "    positions_[x] = list()\n",
    "    id_[x]        = list()\n",
    "    cpu_[x]       = list()\n",
    "    id0_[x]       = list()\n",
    "    cpu0_[x]      = list()\n",
    "    \n",
    "\n",
    "for k in range(0, nop+1):\n",
    "    data_file = data_files[k]\n",
    "    #ds = yt.load(data_files[-1])\n",
    "    ds = AMReXDataset(data_file)\n",
    "    t = ds.current_time\n",
    "    ad = ds.all_data()\n",
    "    aos = AoS(ad)\n",
    "    for y in range(1,nop+1):\n",
    "        positions_[y].append(aos.particles[y-1].pos)\n",
    "        id_[y].append(aos.particles[y-1].id)\n",
    "        cpu_[y].append(aos.particles[y-1].cpu)\n",
    "        id0_[y].append(aos.particles[y-1].id_0)\n",
    "        cpu0_[y].append(aos.particles[y-1].cpu_0)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = dict()\n",
    "y_ = dict()\n",
    "z_ = dict()\n",
    "for v in range(1,nop+1):\n",
    "    x_[v] = np.array([pos[0] for pos in positions_[v]])\n",
    "    y_[v] = np.array([pos[1] for pos in positions_[v]])\n",
    "    z_[v] = np.array([pos[2] for pos in positions_[v]])\n",
    "\n",
    "\n",
    "    \n",
    "for p in range(1, nop+1):\n",
    "    plot(x_[p], y_[p])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(x_[p])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(y_[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(z_[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(id_[p], '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(cpu_[p], '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(id0_[p], '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sorted_       = dict()\n",
    "cpu_sorted_      = dict()\n",
    "position_sorted_ = dict()\n",
    "marker_id_       = dict()\n",
    "marker_cpu_      = dict()\n",
    "\n",
    "x_               = dict()\n",
    "y_               = dict()\n",
    "z_               = dict()\n",
    "\n",
    "marker_posy_ = dict()\n",
    "\n",
    "m_index = dict()\n",
    "\n",
    "\n",
    "for x in range(1,nop+1):\n",
    "    id_sorted_[x]       = list()\n",
    "    cpu_sorted_[x]      = list()\n",
    "    position_sorted_[x] = list()\n",
    "    \n",
    "    \n",
    "prevmarker_id  = -1\n",
    "prevmarker_cpu = -1    \n",
    "\n",
    "#for data_file in data_files:\n",
    "#    ds = AMReXDataset(data_file)\n",
    "#    ad = ds.all_data()\n",
    "\n",
    "for n in range(1, 10):\n",
    "    marker_posy_[n] = list()\n",
    "\n",
    "for n in range(1, 10):\n",
    "    m = (n-1)*1\n",
    "    \n",
    "    data_file = data_files[m]\n",
    "    #ds = yt.load(data_files[-1])\n",
    "    ds = AMReXDataset(data_file)\n",
    "    t = ds.current_time\n",
    "    ad = ds.all_data()\n",
    "    aos = AoS(ad)\n",
    "    prevmarker_id = -1\n",
    "    prevmarker_cpu = -1\n",
    "    for k in range(0, nop):\n",
    "        if aos.particles[k].id_0 == prevmarker_id and aos.particles[k].cpu_0 == prevmarker_cpu:\n",
    "                id_sorted_[1].append(aos.particles[k].id)\n",
    "                cpu_sorted_[1].append(aos.particles[k].cpu)\n",
    "                position_sorted_[1].append(aos.particles[k].pos)\n",
    "                marker_id_[1] = aos.particles[k].id\n",
    "                marker_cpu_[1] = aos.particles[k].cpu\n",
    "                \n",
    "    for i in range(1,nop):    \n",
    "        for k in range(0, nop):\n",
    "            if aos.particles[k].id_0 == marker_id_[i] and aos.particles[k].cpu_0 == marker_cpu_[i]:\n",
    "                id_sorted_[i+1].append(aos.particles[k].id)\n",
    "                cpu_sorted_[i+1].append(aos.particles[k].cpu)\n",
    "                position_sorted_[i+1].append(aos.particles[k].pos)\n",
    "                marker_id_[i+1] = aos.particles[k].id\n",
    "                marker_cpu_[i+1] = aos.particles[k].cpu\n",
    "                \n",
    "    for v in range(1,nop+1):\n",
    "        m_index[v] = v\n",
    "        x_[v] = np.array([pos[0] for pos in position_sorted_[v]])\n",
    "        y_[v] = np.array([pos[1] for pos in position_sorted_[v]])\n",
    "        z_[v] = np.array([pos[2] for pos in position_sorted_[v]])\n",
    "               \n",
    "        marker_posy_[n].append([pos[1] for pos in position_sorted_[v]])\n",
    "        \n",
    "    plot(marker_posy_[n],'-o')  # this is to plot the marker y positions at a given time step to show the flagellum shape\n",
    "    #import time\n",
    "    #time.sleep(1.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_posy_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#print(matplotlib.animation.writers.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['animation.writer'] = 'ffmpeg'\n",
    "#matplotlib.rcParams['animation.writer'] = 'avconv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_                = dict()\n",
    "y_                = dict()\n",
    "z_                = dict()\n",
    "\n",
    "\n",
    "for v in range(1,nop+1):\n",
    "    x_[v] = np.array([pos[0] for pos in position_sorted_[v]])\n",
    "    y_[v] = np.array([pos[1] for pos in position_sorted_[v]])\n",
    "    z_[v] = np.array([pos[2] for pos in position_sorted_[v]])\n",
    "\n",
    "\n",
    "    \n",
    "for p in range(1,nop+1):\n",
    "    plot(x_[p], y_[p], \"-o\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(x_[p])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(y_[p], \".\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(z_[p])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(id_sorted_[p], '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,nop+1):\n",
    "    plot(cpu_sorted_[p], '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Average `vely`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $y$-data might seem smooth. But there will be tiny fluctuations. In order to see those, let's compute the average in dimensions 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_vely = mean(mean(vely[:, :, :], axis=1), axis=1)\n",
    "#              ^^-- returns a 2D array of average velocities\n",
    "#         ^^------- returns a 1D array of average velocities (the average of the previous average)\n",
    "plot(m_vely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute fluctuations: `m_vely` is applied to all `dim=1` slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice-wise subtraction of the average velocity... \n",
    "# I can't think of a fancy pythonic way of doing this => I'll do it in this cumbersome way:\n",
    "fluct_vely = np.zeros_like(vely)\n",
    "for i in range(vely.shape[0]):\n",
    "    for j in range(vely.shape[1]):\n",
    "            fluct_vely[:, i, j] = vely[:, i, j] - m_vely[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(fluct_vely[:, 8, :])\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $x$, $y$ and $z$ Temperatures (Fluctuations in `velx`, `vely`, `velz`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = mean(mean(velx[:, :, :]**2, axis=1), axis=1)\n",
    "#           ^^-- returns a 2D array of average velocities\n",
    "#      ^^------- returns a 1D array of average velocities (the average of the previous average)\n",
    "t_x = sqrt(t_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_y = mean(mean(fluct_vely[:, :, :]**2, axis=1), axis=1)\n",
    "#           ^^-- returns a 2D array of average velocities\n",
    "#      ^^------- returns a 1D array of average velocities (the average of the previous average)\n",
    "t_y = sqrt(t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_z = mean(mean(velz[:, :, :]**2, axis=1), axis=1)\n",
    "#           ^^-- returns a 2D array of average velocities\n",
    "#      ^^------- returns a 1D array of average velocities (the average of the previous average)\n",
    "t_z = sqrt(t_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t_x)\n",
    "plot(t_y)\n",
    "plot(t_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the $x$-fluctuations are supressed due to the wall $\\Rightarrow{}$ needs fixing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Stuff $\\Rightarrow{}$ Clean up at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(phi):\n",
    "    dphi_x = np.zeros_like(phi)\n",
    "    dphi_y = np.zeros_like(phi)\n",
    "    dphi_z = np.zeros_like(phi)\n",
    "    \n",
    "    dphi_x[ :-1, :, :] += phi[1:,   :, :]\n",
    "    dphi_x[1:,   :, :] -= phi[ :-1, :, :]\n",
    "    \n",
    "    dphi_y[:,  :-1, :] += phi[:, 1:,   :]\n",
    "    dphi_y[:, 1:,   :] -= phi[:,  :-1, :]\n",
    "    \n",
    "    dphi_z[:, :,  :-1] += phi[:, :, 1:, ]\n",
    "    dphi_z[:, :, 1:  ] -= phi[:, :,  :-1]\n",
    "    \n",
    "    return dphi_x, dphi_y, dphi_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_x, grad_y, grad_z = grad(cube[\"con\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(cube['con'][32, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_z[32, :, 65:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(cube['con'][43, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_z[43, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(grad_z[43, 30, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_z[32, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(cube['con'][:, :, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_x[:, :, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_coord(i_x, i_y, i_z, dr=dx, r_c=centre_colloid):\n",
    "    x = (i_x + 0.5)*dr[0] - r_c[0]\n",
    "    y = (i_y + 0.5)*dr[1] - r_c[1]\n",
    "    z = (i_z + 0.5)*dr[2] - r_c[2]\n",
    "    \n",
    "    r     = np.sqrt( x**2 + y**2 + z**2)\n",
    "    theta = np.arccos(z/r)\n",
    "    phi   = np.arctan2(y, x)\n",
    "        \n",
    "    return r, theta, phi\n",
    "\n",
    "def r_unit(theta, phi):\n",
    "    return np.array([\n",
    "        np.sin(theta)*np.cos(phi),\n",
    "        np.sin(theta)*np.sin(phi),\n",
    "        np.cos(theta)\n",
    "    ])\n",
    "\n",
    "def theta_unit(theta, phi):\n",
    "    return np.array([\n",
    "        np.cos(theta)*np.cos(phi),\n",
    "        np.cos(theta)*np.sin(phi),\n",
    "       -np.sin(theta)\n",
    "    ])\n",
    "\n",
    "def phi_unit(phi):\n",
    "    return np.array([\n",
    "       -np.sin(phi),\n",
    "        np.cos(phi),\n",
    "        0\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sphere(grad_x, grad_y, grad_z):\n",
    "    grad_r     = np.zeros_like(grad_x)\n",
    "    grad_phi   = np.zeros_like(grad_y)\n",
    "    grad_theta = np.zeros_like(grad_z)\n",
    "    \n",
    "    r_dat     = np.zeros_like(grad_x)\n",
    "    phi_dat   = np.zeros_like(grad_x)\n",
    "    theta_dat = np.zeros_like(grad_x)\n",
    "    \n",
    "    for ind, x in ndenumerate(grad_x):\n",
    "        y = grad_y[ind]\n",
    "        z = grad_z[ind]\n",
    "        \n",
    "        r, theta, phi = sphere_coord(ind[0], ind[1], ind[2])\n",
    "        r_vec     = r_unit(theta, phi)\n",
    "        theta_vec = theta_unit(theta, phi)\n",
    "        phi_vec   = phi_unit(phi)\n",
    "        \n",
    "        grad_r[ind]     = np.dot(np.array([x, y, z]), r_vec)\n",
    "        grad_phi[ind]   = np.dot(np.array([x, y, z]), phi_vec)\n",
    "        grad_theta[ind] = np.dot(np.array([x, y, z]), theta_vec)\n",
    "        \n",
    "        r_dat[ind]     = r\n",
    "        phi_dat[ind]   = phi\n",
    "        theta_dat[ind] = theta\n",
    "        \n",
    "    return np.array(grad_r), np.array(grad_phi), np.array(grad_theta), r_dat, phi_dat, theta_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_r, grad_phi, grad_theta, r_dat, phi_dat, theta_dat = grad_sphere(grad_x, grad_y, grad_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(r_dat[32, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(phi_dat[32, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(theta_dat[32, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_norm[43, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_phi[45, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_theta[45, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(grad_theta[45, 32, :])\n",
    "plot(grad_phi[45, 40, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(grad_theta[45, 40, :])\n",
    "plot(grad_phi[45, 40, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_theta[:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(grad_phi[:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(cube['con'][:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(r_dat[:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(theta_dat[:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matshow(phi_dat[:, :, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_theta(r, phi, theta_range, grad_x, grad_y, grad_z, r_c=centre_colloid, dr=dx):\n",
    "    scan = np.zeros_like(theta_range)\n",
    "    \n",
    "    for i, theta in enumerate(theta_range):\n",
    "        x = r_c[0] + r * np.sin(theta)*np.cos(phi)\n",
    "        y = r_c[1] + r * np.sin(theta)*np.sin(phi)\n",
    "        z = r_c[2] + r * np.cos(theta)\n",
    "                \n",
    "        i_x = int(x / dx[0])\n",
    "        i_y = int(y / dx[1])\n",
    "        i_z = int(z / dx[2])\n",
    "        \n",
    "        dphi_x = grad_x[i_x, i_y, i_z]\n",
    "        dphi_y = grad_y[i_x, i_y, i_z]\n",
    "        dphi_z = grad_z[i_x, i_y, i_z]\n",
    "        \n",
    "        e_theta = theta_unit(theta, phi)\n",
    "        scan[i] = np.dot(np.array([dphi_x, dphi_y, dphi_z]), -e_theta)\n",
    "    \n",
    "    return scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, np.pi, num=100)\n",
    "y_1 = scan_theta(1.4e-3, 0.0, x, grad_x, grad_y, grad_z)\n",
    "y_2 = scan_theta(1.4e-3, 0.5, x, grad_x, grad_y, grad_z)\n",
    "y_3 = scan_theta(1.4e-3, 1, x, grad_x, grad_y, grad_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.pi-x, y_1)\n",
    "plot(np.pi-x, y_2)\n",
    "plot(np.pi-x, y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = np.abs(r_dat - 1.1e-3) < 1e-3\n",
    "sum(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_sel = theta_dat[sel]\n",
    "phi_sel   = phi_dat[sel]\n",
    "\n",
    "grad_norm_sel  = grad_norm[sel]\n",
    "grad_phi_sel   = grad_phi[sel]\n",
    "grad_theta_sel = grad_theta[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_selector = np.abs(phi_sel - 0.6) < 1e-3\n",
    "sum(phi_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pts = np.array(sorted(zip(theta_sel[phi_selector], grad_theta_sel[phi_selector])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sorted_pts[:,0], sorted_pts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(theta_sel[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
